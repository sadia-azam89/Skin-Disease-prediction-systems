{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "297a19a1"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "id": "297a19a1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ue6aFWXvOiIf"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "Ue6aFWXvOiIf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7c82a86"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "data_dir = pathlib.Path(\"/kaggle/input/dermnetdataset/DermnetDataset/train\")"
      ],
      "id": "d7c82a86"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3462b9b"
      },
      "outputs": [],
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "id": "e3462b9b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83b70733"
      },
      "outputs": [],
      "source": [
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "# Defining the directories and number of images to display\n",
        "data_dir = Path(\"/content/drive/MyDrive/Dermnetdataset/train\")\n",
        "dirs = [\"Acne and Rosacea Photos\", \"Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions\", \"Atopic Dermatitis Photos\",\"Eczema Photos\",\"Hair Loss Photos Alopecia and other Hair Diseases\",\"Melanoma Skin Cancer Nevi and Moles\",\"Psoriasis pictures Lichen Planus and related diseases\",\"Seborrheic Keratoses and other Benign Tumors\",\"Tinea Ringworm Candidiasis and other Fungal Infections\",\"Urticaria Hives\"]\n",
        "num_images = 3\n",
        "\n",
        "# Creating a figure with subplots\n",
        "fig, axes = plt.subplots(len(dirs), num_images, figsize=(15, 30))\n",
        "\n",
        "# Loop over the directories and images to display\n",
        "for i, d in enumerate(dirs):\n",
        "    image_paths = list((data_dir / d).glob(\"*\"))\n",
        "    for j in range(num_images):\n",
        "        # Opening the image using PIL and display it on the subplot\n",
        "        img = PIL.Image.open(str(image_paths[j]))\n",
        "        axes[i, j].imshow(img)\n",
        "        axes[i, j].axis(\"off\")\n",
        "        # Adding a title to the subplot with the directory name\n",
        "        if j == 0:\n",
        "            axes[i, j].set_title(d)\n",
        "\n",
        "# Adjusting the spacing and layout of the subplots\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "id": "83b70733"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cefcdb98"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import tensorflow as tf"
      ],
      "id": "cefcdb98"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c94358f6"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "     image_size=(256,256),\n",
        "  subset=\"training\",\n",
        "  seed=123)"
      ],
      "id": "c94358f6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "137248d5"
      },
      "outputs": [],
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "    image_size=(256,256),\n",
        "  subset=\"validation\",\n",
        "  seed=123)"
      ],
      "id": "137248d5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d619bcad"
      },
      "outputs": [],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "id": "d619bcad"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17c6d72c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "id": "17c6d72c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6343929a"
      },
      "outputs": [],
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "id": "6343929a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "324f3470"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "id": "324f3470"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fba8fe5d"
      },
      "outputs": [],
      "source": [
        "normalization_layer = layers.Rescaling(1./255)"
      ],
      "id": "fba8fe5d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1a657eb"
      },
      "outputs": [],
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ],
      "id": "e1a657eb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20iznd4xuIVA"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.2)\n",
        "    ])"
      ],
      "id": "20iznd4xuIVA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kg6t7riCueoX"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = 256\n",
        "CHANNELS = 3"
      ],
      "id": "Kg6t7riCueoX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f009919a"
      },
      "outputs": [],
      "source": [
        "input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
        "num_classes = len(class_names)\n",
        "\n",
        "model = Sequential([\n",
        "  layers.Rescaling(1./255, input_shape=(256, 256, 3)),\n",
        "  layers.BatchNormalization(),\n",
        "\n",
        "  layers.Conv2D(32, 3, padding='same', kernel_regularizer=regularizers.l2(0.01), activation='relu'),\n",
        "  layers.MaxPooling2D((2,2)),\n",
        "\n",
        "  layers.Dropout(0.5),\n",
        "\n",
        "  layers.Conv2D(64, 3, padding='same', kernel_regularizer=regularizers.l2(0.01), activation='relu'),\n",
        "  layers.MaxPooling2D((2,2)),\n",
        "\n",
        "  layers.Conv2D(64, 3, padding='same', kernel_regularizer=regularizers.l2(0.01), activation='relu'),\n",
        "  layers.MaxPooling2D((2,2)),\n",
        "\n",
        "  layers.Conv2D(64, 3, padding='same', kernel_regularizer=regularizers.l2(0.01), activation='relu'),\n",
        "  layers.MaxPooling2D((2,2)),\n",
        "\n",
        "  layers.Dropout(0.5),\n",
        "\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "  layers.BatchNormalization(),\n",
        "  layers.Dense(num_classes)\n",
        "])\n",
        "model.build(input_shape=input_shape)"
      ],
      "id": "f009919a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c97bd95"
      },
      "outputs": [],
      "source": [
        "\n",
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "id": "3c97bd95"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c86f48c4"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='sgd',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "id": "c86f48c4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4583eae6"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ],
      "id": "4583eae6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHijwW4mNIiM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import regularizers"
      ],
      "id": "fHijwW4mNIiM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzivIAMzna05"
      },
      "outputs": [],
      "source": [
        "custom_early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    min_delta=0.001,\n",
        "    mode='min'\n",
        ")"
      ],
      "id": "FzivIAMzna05"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3d56e2f"
      },
      "outputs": [],
      "source": [
        "epochs=22\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs,\n",
        "  verbose=1,\n",
        "  callbacks=[custom_early_stopping]\n",
        ")"
      ],
      "id": "e3d56e2f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8835115"
      },
      "outputs": [],
      "source": [
        "model.save(\"skin.h5\")"
      ],
      "id": "f8835115"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51529ab6"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "id": "51529ab6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a1a5975"
      },
      "outputs": [],
      "source": [
        "fil = \"/content/drive/MyDrive/Dermnetdataset/test/Eczema Photos/03DermatitisArm1.jpg\"\n",
        "\n",
        "img = tf.keras.utils.load_img(\n",
        "    fil, target_size=(256, 256)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {}.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "id": "1a1a5975"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab1ce1cb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.metrics import Metric\n",
        "from tensorflow.python.keras.utils import losses_utils\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class F1Score(Metric):\n",
        "    def __init__(self, name='f1_score', **kwargs):\n",
        "        super(F1Score, self).__init__(name=name, **kwargs)\n",
        "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
        "        self.false_positives = self.add_weight(name='fp', initializer='zeros')\n",
        "        self.false_negatives = self.add_weight(name='fn', initializer='zeros')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_pred = tf.cast(tf.round(y_pred), tf.float32)\n",
        "\n",
        "        true_positives = tf.reduce_sum(y_true * y_pred)\n",
        "        false_positives = tf.reduce_sum((1 - y_true) * y_pred)\n",
        "        false_negatives = tf.reduce_sum(y_true * (1 - y_pred))\n",
        "\n",
        "        self.true_positives.assign_add(true_positives)\n",
        "        self.false_positives.assign_add(false_positives)\n",
        "        self.false_negatives.assign_add(false_negatives)\n",
        "\n",
        "    def result(self):\n",
        "        precision = self.true_positives / (self.true_positives + self.false_positives + losses_utils.epsilon())\n",
        "        recall = self.true_positives / (self.true_positives + self.false_negatives + losses_utils.epsilon())\n",
        "\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall + losses_utils.epsilon())\n",
        "        return f1_score\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super(F1Score, self).get_config()\n",
        "        return {**base_config}\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[F1Score()])\n"
      ],
      "id": "ab1ce1cb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d783f23"
      },
      "outputs": [],
      "source": [
        "model.save(\"skin_model.h5\")"
      ],
      "id": "7d783f23"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c948aea5"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\"/content/skin.h5\")"
      ],
      "id": "c948aea5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8df77f4c"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "\n",
        "model = tf.keras.models.load_model('/content/skin.h5')\n",
        "\n",
        "image_path = '/content/drive/MyDrive/Dermnetdataset/train/Eczema Photos/Dyshidrosis-20.jpg'\n",
        "image = load_img(image_path, target_size=(256, 256))\n",
        "image_array = img_to_array(image)\n",
        "input_data = image_array.reshape(1, 256, 256, 3)\n",
        "\n",
        "predictions = model.predict(input_data)\n",
        "print(predictions)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "print(score)"
      ],
      "id": "8df77f4c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc5e09c4"
      },
      "outputs": [],
      "source": [
        "print(\n",
        "    \"This image most likely belongs to {}.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "id": "bc5e09c4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c9e06fd"
      },
      "outputs": [],
      "source": [
        "fil = \"/content/drive/MyDrive/Dermnetdataset/train/Seborrheic Keratoses and other Benign Tumors/accessory-trachus-4.jpg\"\n",
        "\n",
        "img = tf.keras.utils.load_img(\n",
        "    fil, target_size=(256, 256)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {}.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "id": "5c9e06fd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8oDS_POE5X7"
      },
      "outputs": [],
      "source": [
        "fil = \"/content/drive/MyDrive/Dermnetdataset/train/Tinea Ringworm Candidiasis and other Fungal Infections/13TineaGroin143.jpg\"\n",
        "\n",
        "img = tf.keras.utils.load_img(\n",
        "    fil, target_size=(256, 256)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {}.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "id": "X8oDS_POE5X7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkR24tdBJXnQ"
      },
      "outputs": [],
      "source": [
        "fil = \"/content/drive/MyDrive/Dermnetdataset/train/Acne and Rosacea Photos/07Rhinophymaq.jpg\"\n",
        "\n",
        "img = tf.keras.utils.load_img(\n",
        "    fil, target_size=(256, 256)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {}.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "id": "JkR24tdBJXnQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFqFg79sJXnQ"
      },
      "outputs": [],
      "source": [
        "fil = \"/content/drive/MyDrive/Dermnetdataset/train/Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions/actinic-cheilitis-sq-cell-lip-145.jpg\"\n",
        "\n",
        "img = tf.keras.utils.load_img(\n",
        "    fil, target_size=(256, 256)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {}.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "id": "zFqFg79sJXnQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuY-p2_XJXnR"
      },
      "outputs": [],
      "source": [
        "fil = \"/content/drive/MyDrive/Dermnetdataset/train/Hair Loss Photos Alopecia and other Hair Diseases/acne-keloidalis-11.jpg\"\n",
        "img = tf.keras.utils.load_img(\n",
        "    fil, target_size=(256, 256)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {}.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "id": "KuY-p2_XJXnR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmoHjimXJXnR"
      },
      "outputs": [],
      "source": [
        "fil = \"/content/drive/MyDrive/Dermnetdataset/train/Psoriasis pictures Lichen Planus and related diseases/08LichenPlanusTongue.jpg\"\n",
        "img = tf.keras.utils.load_img(\n",
        "    fil, target_size=(256, 256)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {}.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "id": "FmoHjimXJXnR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnRfEoM9JXnR"
      },
      "outputs": [],
      "source": [
        "fil = \"/content/drive/MyDrive/Dermnetdataset/train/Tinea Ringworm Candidiasis and other Fungal Infections/13Candida040701.jpg\"\n",
        "img = tf.keras.utils.load_img(\n",
        "    fil, target_size=(256, 256)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {}.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "id": "YnRfEoM9JXnR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ga_N6_6UJXnS"
      },
      "outputs": [],
      "source": [
        "fil = \"/content/drive/MyDrive/Dermnetdataset/train/Urticaria Hives/PUPPP-12.jpg\"\n",
        "img = tf.keras.utils.load_img(\n",
        "    fil, target_size=(256, 256)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {}.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "id": "ga_N6_6UJXnS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6roeShPme2J"
      },
      "outputs": [],
      "source": [
        "# Convert to TensorFlow Lite (Optional)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TensorFlow Lite model to a file\n",
        "with open('model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n"
      ],
      "id": "r6roeShPme2J"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 6153.622505,
      "end_time": "2023-05-10T19:08:57.939521",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-05-10T17:26:24.317016",
      "version": "2.4.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}